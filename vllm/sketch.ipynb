{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rog0d/miniconda3/envs/vllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-12 21:00:58,848\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-12 21:01:03 arg_utils.py:957] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 11-12 21:01:03 config.py:1021] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 11-12 21:01:03 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 11-12 21:01:06 model_runner.py:1056] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\n",
      "INFO 11-12 21:01:06 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.50it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  2.08it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-12 21:03:07 model_runner.py:1067] Loading model weights took 6.0160 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-12 21:03:07 gpu_executor.py:122] # GPU blocks: 37315, # CPU blocks: 2340\n",
      "INFO 11-12 21:03:07 gpu_executor.py:126] Maximum concurrency for 131072 tokens per request: 4.56x\n",
      "INFO 11-12 21:03:10 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-12 21:03:10 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-12 21:03:22 model_runner.py:1523] Graph capturing finished in 12 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# llama-3-70 quantized\n",
    "llm = LLM(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "#llm = LLM('meta-llama/Llama-3.2-1B-Instruct', gpu_memory_utilization=0.9, tensor_parallel_size=8, enforce_eager=False, dtype=\"half\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling FSM index for all state transitions: 100%|██████████| 3/3 [00:00<00:00,  6.71it/s]ut: 0.00 toks/s]\n",
      "Compiling FSM index for all state transitions: 100%|██████████| 4/4 [00:00<00:00,  8.45it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [01:43<00:00, 103.94s/it, est. speed input: 1.67 toks/s, output: 4.81 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for inference: 104.51963531202637 seconds\n",
      "Grammar is well-written.\n",
      "Generated text without parser: 'features\\n    CPU\\n       mandatory\\n           ClockSpeed\\n       optional\\n           HyperThreading\\n               alternative\\n                   TurboBoost\\n                   IntegratedGraphics\\n       Memory\\n           mandatory\\n               RAM\\n       optional\\n                   Storage\\n                       alternative\\n                           SSDHDD\\n                           NVMeSSD\\n   PowerSupply\\n       mandatory\\n           Voltage\\n       optional\\n           PowerSharing\\n               alternative\\n                   Overclocking\\n   Display\\n       mandatory\\n           Resolution\\n       optional\\n                   Brightness\\n                       alternative\\n                           Touchscreen\\n                           HDRDisplay\\n   OperatingSystem\\n       mandatory\\n           Stability\\n       optional\\n                   Security\\n                       alternative\\n                           CustomizationOptions\\n                           BiometricAuthentication\\n   Networking\\n       mandatory\\n           Connectivity\\n       optional\\n                   Wireless\\n                       alternative\\n                           Bluetooth\\n                           Ethernet\\n   Ports\\n       mandatory\\n           USB\\n       optional\\n                   DisplayPort\\n                       alternative\\n                           HDMI\\n                           Thunderbolt\\n   Battery\\n       mandatory\\n           Capacity\\n       optional\\n                   ChargeTime\\n                       alternative\\n                           WirelessCharging\\n                           FastCharging\\n   Camera\\n       mandatory\\n           Resolution\\n       optional\\n                   Lens\\n                       alternative\\n                           ImageStabilization\\n                           OpticalZoom\\n   Sound\\n       mandatory\\n           Speakers\\n       optional\\n                   HeadphonesJack\\n                       alternative\\n                           SurroundSound\\n                           AudioCodec\\n   Peripherals\\n       mandatory\\n           Keyboard\\n       optional\\n                   Touchpad\\n                       alternative\\n                           BiometricAuthentication\\n                           BacklitKeys\\n   Biometric\\n       mandatory\\n           FingerprintSensor\\n       optional\\n                   FaceRecognition\\n                       alternative\\n                           IrisScanner\\n                           VoiceRecognition\\n   Warranty\\n       mandatory\\n           Years\\n       optional\\n                   Support\\n                       alternative\\n                           RepairService\\n                           ReplacementPolicy\\n       WarrantyType\\n           mandatory\\n               Manufacturer\\n       optional\\n                   Carrier\\n                       alternative\\n                           Extended\\n                           FreeVirtualSupport\\n           ExpirationDate\\n           mandatory\\n               Single\\n       optional\\n                   Multiple\\n                       alternative\\n                           Priority\\n                           Premium\\n       ReturnPolicy\\n           mandatory\\n               Refund\\n       optional\\n                   Repair\\n                       alternative\\n                           Exchange\\n                           ConcectionCost\\n       ExtendedWarranty\\n           mandatory\\n               Duration\\n       optional\\n                   Coverage\\n                       alternative\\n                           Exclusive\\n                           PlusOptions\\n       ServiceTime\\n           mandatory\\n               Response\\n       optional\\n                   Documentation\\n                       alternative'\n",
      "Generation not grammatically valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_seed = random.randint(0, 10000)\n",
    "random.seed(random_seed)\n",
    "\n",
    "print(f\"seed: {random_seed}\")\n",
    "\n",
    "uvl_grammar_no_indent = r\"\"\"\n",
    "?start: _NL* featuremodel\n",
    "\n",
    "featuremodel: \"features\" _NL [feature+]\n",
    "feature: NAME _NL (group+)?\n",
    "\n",
    "group: \"or\" groupspec          -> or_group\n",
    "    | \"alternative\" groupspec -> alternative_group\n",
    "    | \"optional\" groupspec    -> optional_group\n",
    "    | \"mandatory\" groupspec   -> mandatory_group\n",
    "    | cardinality groupspec    -> cardinality_group\n",
    "\n",
    "groupspec: _NL feature+\n",
    "\n",
    "cardinality: \"[\" INT (\"..\" (INT | \"*\"))? \"]\"\n",
    "\n",
    "%import common.INT\n",
    "%import common.CNAME -> NAME\n",
    "%import common.WS_INLINE\n",
    "%ignore WS_INLINE\n",
    "\n",
    "_NL: /\\r?\\n[ \\t]*/\n",
    "\"\"\"\n",
    "\n",
    "uvl_grammar = r\"\"\"\n",
    "?start: _NL* featuremodel\n",
    "\n",
    "featuremodel: \"features\" _NL [\"->\" feature+ \"<-\"]\n",
    "feature: NAME _NL (\"->\" group+ \"<-\")?\n",
    "\n",
    "group: \"or\" groupspec          -> or_group\n",
    "    | \"alternative\" groupspec -> alternative_group\n",
    "    | \"optional\" groupspec    -> optional_group\n",
    "    | \"mandatory\" groupspec   -> mandatory_group\n",
    "    | cardinality groupspec    -> cardinality_group\n",
    "\n",
    "groupspec: _NL \"->\" feature+ \"<-\"\n",
    "\n",
    "cardinality: \"[\" INT (\"..\" (INT | \"*\"))? \"]\"\n",
    "\n",
    "%import common.INT\n",
    "%import common.CNAME -> NAME\n",
    "%import common.WS_INLINE\n",
    "%ignore WS_INLINE\n",
    "\n",
    "_NL: /\\r?\\n[ \\t]*/\n",
    "\"\"\"\n",
    "\n",
    "uvl_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant for creating sintactically correct expressions similar to these examples:\n",
    "\n",
    "features\n",
    "    Sandwich\n",
    "        mandatory\n",
    "            Bread\n",
    "        optional\n",
    "            Sauce\n",
    "                alternative\n",
    "                    Ketchup\n",
    "                    Mustard\n",
    "            Cheese\n",
    "constraints\n",
    "    Ketchup => Cheese\n",
    ",\n",
    "features\n",
    "\tSmartWatch\n",
    "\t\tmandatory\n",
    "\t\t\tFunctionalities \n",
    "\t\t\t\tmandatory\n",
    "\t\t\t\t\tFitnessMonitor\n",
    "\t\t\t\t\tSleepTracker\n",
    "\t\t\t\t\tVibrateAlert\n",
    "\t\t\t\t\t\tmandatory\n",
    "\t\t\t\t\t\t\tCall\n",
    "\t\t\t\t\t\t\tNotification\n",
    "\t\t\tSensors\n",
    "\t\t\t\tmandatory\n",
    "\t\t\t\t\tPedometer\n",
    "\t\t\t\t\tAccelerometer\n",
    "\t\t\t\toptional\n",
    "\t\t\t\t\tHeartRateSensor\n",
    "\t\t\tConnectivity\n",
    "\t\t\t\tmandatory\n",
    "\t\t\t\t\tBT40\n",
    "\n",
    "\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Write new, valid expressions for a computer: \n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "arithmetic_grammar = \"\"\"\n",
    "?start: comparison\n",
    "\n",
    "?comparison: expression (\"=\" expression)?\n",
    "\n",
    "?expression: term ((\"+\" | \"-\") term)*\n",
    "\n",
    "?term: factor ((\"*\" | \"/\") factor)*\n",
    "\n",
    "?factor: NUMBER\n",
    "       | \"-\" factor\n",
    "       | \"(\" comparison \")\"\n",
    "\n",
    "%import common.NUMBER\n",
    "%ignore \" \"  // Ignore spaces\n",
    "\n",
    "\"\"\"\n",
    "arithmetic_prompt=\"Rewrite 5*5 as another expression\"\n",
    "\n",
    "arithmetic_prompt_fewshots=\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant for creating gramatically, equivalent and correct arithmetical expression<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Rewrite the following expressions into equivalent ones as show in this example(5*5)=(5+5+5+5+5)=(25*1)=(5*3)+(5*2).\\n(3*3)=\\n(3*4*5)=\\n(7*3)=\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "sql_grammar=\"\"\"\n",
    "start: select_statement\n",
    "select_statement: \"SELECT\" column \"from\" table \"where\" condition\n",
    "column: \"col_1\" | \"col_2\"\n",
    "table: \"table_1\" | \"table_2\"\n",
    "condition: column \"=\" number\n",
    "number: \"1\" | \"2\"\n",
    "\"\"\"\n",
    "sql_prompt=\"Generate a sql state that select col_1 from table_1 where it is equals to 1\"\n",
    "\n",
    "import time\n",
    "start_time = time.perf_counter()\n",
    "grammar = uvl_grammar_no_indent\n",
    "prompt = uvl_prompt\n",
    "# llama-3 8B\n",
    "#MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "#llm = LLM(MODEL, gpu_memory_utilization=1, tensor_parallel_size=8, enforce_eager=False, dtype=\"half\") \n",
    "\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "        max_tokens=500,\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        min_tokens=200,\n",
    "    )\n",
    "\n",
    "\n",
    "outputs = llm.generate(\n",
    "    prompts=prompt,\n",
    "    sampling_params=sampling_params,\n",
    "    guided_options_request=dict(guided_grammar=grammar))\n",
    "\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(f'Elapsed time for inference: {elapsed_time} seconds')\n",
    "\n",
    "from lark import Lark, exceptions\n",
    "from lark.indenter import Indenter\n",
    "\n",
    "\n",
    "def test(generation: str, parser):\n",
    "    print(parser.parse(generation).pretty())\n",
    "\n",
    "\"\"\"\n",
    "class TreeIndenter(Indenter):\n",
    "    NL_type = '_NL'\n",
    "    OPEN_PAREN_types = []\n",
    "    CLOSE_PAREN_types = []\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    tab_len = 8\n",
    "\"\"\"\n",
    "\n",
    "#parser = Lark(grammar, parser='lalr', postlex=TreeIndenter())\n",
    "parser = Lark(grammar, parser='lalr')\n",
    "\n",
    "print(\"Grammar is well-written.\")\n",
    "\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Generated text without parser: {generated_text!r}\")\n",
    "\n",
    "    try:\n",
    "        # Parse a generation\n",
    "        test(generation=generated_text, parser=parser)\n",
    "\n",
    "    except:\n",
    "        print(\"Generation not grammatically valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nº of generated tokens: 500\n",
      "generated tokens id: (20922, 198, 262, 220, 32715, 198, 286, 81216, 198, 310, 27196, 11303, 198, 286, 13099, 198, 310, 75046, 1016, 6285, 198, 394, 78095, 198, 504, 38062, 754, 53463, 198, 504, 83537, 21309, 198, 286, 10869, 198, 310, 81216, 198, 394, 35005, 198, 286, 13099, 198, 504, 5913, 198, 667, 78095, 198, 1014, 1242, 52426, 4195, 198, 1014, 37426, 7979, 1242, 35, 198, 262, 15335, 52396, 198, 286, 81216, 198, 310, 95443, 198, 286, 13099, 198, 310, 15335, 84856, 198, 394, 78095, 198, 504, 1959, 21321, 287, 198, 262, 7165, 198, 286, 81216, 198, 310, 39206, 198, 286, 13099, 198, 504, 94347, 198, 667, 78095, 198, 1014, 11561, 8337, 198, 1014, 71388, 7165, 198, 262, 59247, 2374, 198, 286, 81216, 198, 310, 626, 2968, 198, 286, 13099, 198, 504, 15712, 198, 667, 78095, 198, 1014, 10480, 2065, 3883, 198, 1014, 37196, 24264, 19855, 198, 262, 79107, 198, 286, 81216, 198, 310, 14953, 1968, 198, 286, 13099, 198, 504, 38945, 1752, 198, 667, 78095, 198, 1014, 47182, 198, 1014, 99106, 198, 262, 69373, 198, 286, 81216, 198, 310, 27123, 198, 286, 13099, 198, 504, 7165, 7229, 198, 667, 78095, 198, 1014, 39, 32989, 198, 1014, 97012, 53533, 198, 262, 70363, 198, 286, 81216, 198, 310, 30492, 198, 286, 13099, 198, 504, 56463, 1489, 198, 667, 78095, 198, 1014, 38945, 1752, 1163, 75816, 198, 1014, 33274, 1163, 75816, 198, 262, 13751, 198, 286, 81216, 198, 310, 39206, 198, 286, 13099, 198, 504, 99205, 198, 667, 78095, 198, 1014, 1945, 626, 13052, 2065, 198, 1014, 22078, 950, 26728, 198, 262, 16493, 198, 286, 81216, 198, 310, 20298, 8476, 198, 286, 13099, 198, 504, 12626, 17144, 33731, 198, 667, 78095, 198, 1014, 23912, 1067, 16493, 198, 1014, 15097, 38013, 198, 262, 3976, 70072, 198, 286, 81216, 198, 310, 19448, 198, 286, 13099, 198, 504, 11561, 13545, 198, 667, 78095, 198, 1014, 37196, 24264, 19855, 198, 1014, 3792, 32735, 9026, 198, 262, 37196, 24264, 198, 286, 81216, 198, 310, 37, 49018, 31852, 198, 286, 13099, 198, 504, 16680, 62392, 198, 667, 78095, 198, 1014, 40, 6091, 32102, 198, 1014, 52267, 62392, 198, 262, 54, 44290, 198, 286, 81216, 198, 310, 55519, 198, 286, 13099, 198, 504, 8075, 198, 667, 78095, 198, 1014, 99486, 1898, 198, 1014, 69669, 14145, 198, 286, 54, 44290, 941, 198, 310, 81216, 198, 394, 62548, 198, 286, 13099, 198, 504, 97394, 198, 667, 78095, 198, 1014, 54290, 198, 1014, 11180, 34126, 8075, 198, 310, 67401, 1956, 198, 310, 81216, 198, 394, 11126, 198, 286, 13099, 198, 504, 33189, 198, 667, 78095, 198, 1014, 21197, 198, 1014, 67567, 198, 286, 5715, 14145, 198, 310, 81216, 198, 394, 4032, 1263, 198, 286, 13099, 198, 504, 99486, 198, 667, 78095, 198, 1014, 32664, 198, 1014, 1128, 346, 407, 15289, 198, 286, 54290, 54, 44290, 198, 310, 81216, 198, 394, 13242, 198, 286, 13099, 198, 504, 67412, 198, 667, 78095, 198, 1014, 71505, 198, 1014, 22560, 3883, 198, 286, 1898, 1489, 198, 310, 81216, 198, 394, 2647, 198, 286, 13099, 198, 504, 65434, 198, 667, 78095)\n"
     ]
    }
   ],
   "source": [
    "print(f\"nº of generated tokens: {str(len(outputs[0].outputs[0].token_ids))}\")\n",
    "print(f\"generated tokens id: {outputs[0].outputs[0].token_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "    CPU\n",
      "       mandatory\n",
      "           ClockSpeed\n",
      "       optional\n",
      "           HyperThreading\n",
      "               alternative\n",
      "                   TurboBoost\n",
      "                   IntegratedGraphics\n",
      "       Memory\n",
      "           mandatory\n",
      "               RAM\n",
      "       optional\n",
      "                   Storage\n",
      "                       alternative\n",
      "                           SSDHDD\n",
      "                           NVMeSSD\n",
      "   PowerSupply\n",
      "       mandatory\n",
      "           Voltage\n",
      "       optional\n",
      "           PowerSharing\n",
      "               alternative\n",
      "                   Overclocking\n",
      "   Display\n",
      "       mandatory\n",
      "           Resolution\n",
      "       optional\n",
      "                   Brightness\n",
      "                       alternative\n",
      "                           Touchscreen\n",
      "                           HDRDisplay\n",
      "   OperatingSystem\n",
      "       mandatory\n",
      "           Stability\n",
      "       optional\n",
      "                   Security\n",
      "                       alternative\n",
      "                           CustomizationOptions\n",
      "                           BiometricAuthentication\n",
      "   Networking\n",
      "       mandatory\n",
      "           Connectivity\n",
      "       optional\n",
      "                   Wireless\n",
      "                       alternative\n",
      "                           Bluetooth\n",
      "                           Ethernet\n",
      "   Ports\n",
      "       mandatory\n",
      "           USB\n",
      "       optional\n",
      "                   DisplayPort\n",
      "                       alternative\n",
      "                           HDMI\n",
      "                           Thunderbolt\n",
      "   Battery\n",
      "       mandatory\n",
      "           Capacity\n",
      "       optional\n",
      "                   ChargeTime\n",
      "                       alternative\n",
      "                           WirelessCharging\n",
      "                           FastCharging\n",
      "   Camera\n",
      "       mandatory\n",
      "           Resolution\n",
      "       optional\n",
      "                   Lens\n",
      "                       alternative\n",
      "                           ImageStabilization\n",
      "                           OpticalZoom\n",
      "   Sound\n",
      "       mandatory\n",
      "           Speakers\n",
      "       optional\n",
      "                   HeadphonesJack\n",
      "                       alternative\n",
      "                           SurroundSound\n",
      "                           AudioCodec\n",
      "   Peripherals\n",
      "       mandatory\n",
      "           Keyboard\n",
      "       optional\n",
      "                   Touchpad\n",
      "                       alternative\n",
      "                           BiometricAuthentication\n",
      "                           BacklitKeys\n",
      "   Biometric\n",
      "       mandatory\n",
      "           FingerprintSensor\n",
      "       optional\n",
      "                   FaceRecognition\n",
      "                       alternative\n",
      "                           IrisScanner\n",
      "                           VoiceRecognition\n",
      "   Warranty\n",
      "       mandatory\n",
      "           Years\n",
      "       optional\n",
      "                   Support\n",
      "                       alternative\n",
      "                           RepairService\n",
      "                           ReplacementPolicy\n",
      "       WarrantyType\n",
      "           mandatory\n",
      "               Manufacturer\n",
      "       optional\n",
      "                   Carrier\n",
      "                       alternative\n",
      "                           Extended\n",
      "                           FreeVirtualSupport\n",
      "           ExpirationDate\n",
      "           mandatory\n",
      "               Single\n",
      "       optional\n",
      "                   Multiple\n",
      "                       alternative\n",
      "                           Priority\n",
      "                           Premium\n",
      "       ReturnPolicy\n",
      "           mandatory\n",
      "               Refund\n",
      "       optional\n",
      "                   Repair\n",
      "                       alternative\n",
      "                           Exchange\n",
      "                           ConcectionCost\n",
      "       ExtendedWarranty\n",
      "           mandatory\n",
      "               Duration\n",
      "       optional\n",
      "                   Coverage\n",
      "                       alternative\n",
      "                           Exclusive\n",
      "                           PlusOptions\n",
      "       ServiceTime\n",
      "           mandatory\n",
      "               Response\n",
      "       optional\n",
      "                   Documentation\n",
      "                       alternative\n"
     ]
    },
    {
     "ename": "UnexpectedToken",
     "evalue": "Unexpected token Token('$END', '') at line 142, column 24.\nExpected one of: \n\t* _NL\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/parsers/lalr_parser_state.py:77\u001b[0m, in \u001b[0;36mParserState.feed_token\u001b[0;34m(self, token, is_end)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     action, arg \u001b[38;5;241m=\u001b[39m \u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '$END'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m gen \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(gen)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpretty())\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/lark.py:655\u001b[0m, in \u001b[0;36mLark.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, start: Optional[\u001b[38;5;28mstr\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, on_error: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptional[Callable[[UnexpectedInput], bool]]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParseTree\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given text, according to the options provided.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/parser_frontends.py:104\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    102\u001b[0m kw \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_error\u001b[39m\u001b[38;5;124m'\u001b[39m: on_error}\n\u001b[1;32m    103\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_lexer_thread(text)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:42\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[0;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, lexer, start, on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:88\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[0;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_interactive:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state\u001b[38;5;241m.\u001b[39mlexer)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:111\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:105\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m    102\u001b[0m         state\u001b[38;5;241m.\u001b[39mfeed_token(token)\n\u001b[1;32m    104\u001b[0m     end_token \u001b[38;5;241m=\u001b[39m Token\u001b[38;5;241m.\u001b[39mnew_borrow_pos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$END\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, token) \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;28;01melse\u001b[39;00m Token(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$END\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm/lib/python3.10/site-packages/lark/parsers/lalr_parser_state.py:80\u001b[0m, in \u001b[0;36mParserState.feed_token\u001b[0;34m(self, token, is_end)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     expected \u001b[38;5;241m=\u001b[39m {s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m states[state]\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39misupper()}\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, expected, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, interactive_parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m arg \u001b[38;5;241m!=\u001b[39m end_state\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m Shift:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# shift once and return\u001b[39;00m\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m: Unexpected token Token('$END', '') at line 142, column 24.\nExpected one of: \n\t* _NL\n"
     ]
    }
   ],
   "source": [
    "gen = outputs[0].outputs[0].text\n",
    "print(f\"{str(gen)}\")\n",
    "\n",
    "print(parser.parse(gen).pretty())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
